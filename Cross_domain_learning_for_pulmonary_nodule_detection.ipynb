{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Y9Yab7hHYA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "file = h5py.File('drive/My Drive/New Data (test)/flower-river.h5', 'r')\n",
        "list(file.values())"
      ],
      "metadata": {
        "id": "tQuJ8BY2f1Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-io"
      ],
      "metadata": {
        "id": "9FVo5xq2w9WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enF2kBPBKHfX"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "# Load HDF5 dataset\n",
        "h5f_train_X = tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/train.h5', '/X')\n",
        "h5f_train_Y = tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/train.h5', '/Y')\n",
        "\n",
        "\n",
        "h5f_test_X=tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/test.h5', '/X')\n",
        "h5f_test_Y=tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/test.h5', '/Y')\n",
        "\n",
        "h5f_val_X=tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/val.h5', '/X')\n",
        "h5f_val_Y=tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/val.h5', '/Y')\n",
        "\n",
        "\n",
        "h5f_val_fr_X=tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/flower-river.h5', '/X')\n",
        "h5f_val_fr_Y=tfio.IODataset.from_hdf5('drive/My Drive/New Data (test)/flower-river.h5', '/Y')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Zip together samples and corresponding labels\n",
        "train = tf.data.Dataset.zip((h5f_train_X ,h5f_train_Y)).batch(5187, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test = tf.data.Dataset.zip((h5f_test_X,h5f_test_Y)).batch(1622, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val = tf.data.Dataset.zip((h5f_val_X,h5f_val_Y)).batch(1297, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "fr_autoEnc= tf.data.Dataset.zip((h5f_val_fr_X,h5f_val_fr_X)).batch(400, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "fr= tf.data.Dataset.zip((h5f_val_fr_X,h5f_val_fr_Y)).batch(400, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train"
      ],
      "metadata": {
        "id": "UeHbaHJYm65p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brZiiieDKSc0"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model,Sequential\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 200\n",
        "inChannel = 1\n",
        "x, y = 50,50\n",
        "input_img = Input(shape = (x, y, inChannel))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDOYijfJKW4t"
      },
      "source": [
        "def encoder(input_img):\n",
        "    #encoder\n",
        "    conv1 = Conv2D(32, (5, 5), activation='relu', padding='same')(input_img) #28 x 28 x 100\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 100\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 150\n",
        "    pool2 = MaxPooling2D(pool_size=(5, 5))(conv2) #7 x 7 x 150\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 200 (small and thick)\n",
        "    return conv3\n",
        "  \n",
        "def decoder(conv3):    \n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 200  \n",
        "    up1 = UpSampling2D((5,5))(conv4) #14 x 14 x 150\n",
        "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) #7 x 7 x 150\n",
        "    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 100\n",
        "    conv6 = Conv2D(32, (5, 5), activation='relu', padding='same')(up2) # 14 x 14 x 100\n",
        "    decoded = Conv2D(1, (5, 5), activation='relu', padding='same')(conv6) # 28 x 28 x 1\n",
        "    return decoded\n",
        "\n",
        "def fc(encoded):\n",
        "    flat=Flatten()(encoded)\n",
        "    dp = Dropout(0.4, seed=42)(flat)\n",
        "    den1 = Dense(256, activation='relu')(dp)\n",
        "    den2=Dense(2, activation='softmax')(den1)\n",
        "    return den2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo-or8NOKaxF"
      },
      "source": [
        "autoencoder=Model(input_img, decoder(encoder(input_img)))\n",
        "autoencoder.compile(loss='mean_squared_error', optimizer = 'adam')\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym6GmDFCKfVK"
      },
      "source": [
        "aut_train=autoencoder.fit(fr_autoEnc, batch_size=128 ,epochs=200, shuffle=\"batch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL8QXXbfLvXD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "decoded_imgs = autoencoder.predict(X_test_images[100:])\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(10):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    if np.array_equal(Y_f_labels[i+110],[1., 0.]):\n",
        "      ax.set_title(\"River\")\n",
        "    else:\n",
        "      ax.set_title(\"Flower\")\n",
        "    plt.imshow(X_f_images[i+110].reshape(50, 50))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n+1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(50, 50))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYirYqQlNcnw"
      },
      "source": [
        "encode=encoder(input_img)\n",
        "model = Model(input_img, fc(encode))\n",
        "for l1,l2 in zip(model.layers[0:6],autoencoder.layers[0:6]):\n",
        "    l1.set_weights(l2.get_weights())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftwADpDcNije"
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=opt ,metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCxnhsjpOxzm"
      },
      "source": [
        "model.fit(fr,\n",
        "          batch_size=128,\n",
        "          epochs=200,\n",
        "          shuffle='batch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjnvcUR-Nlqm"
      },
      "source": [
        "history=model.fit(train,\n",
        "          batch_size=128,\n",
        "          epochs=200,\n",
        "          shuffle='batch',\n",
        "          validation_data=(val),class_weight={0:1, 1:6})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZBGp7tAOHG4"
      },
      "source": [
        "from keras.models import load_model\n",
        "score = model.evaluate(test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW-Mk7_GXGE-"
      },
      "source": [
        "y_pred = np.argmax(Y_test_labels, axis=1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "predictions_friv=model.predict(X_test_images)\n",
        "matrix_friv = confusion_matrix(y_pred, predictions_friv.argmax(axis=1))\n",
        "sns.heatmap(matrix_friv, cmap=\"Blues\",annot=True, fmt=\".0f\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOgiwqFKXtLX"
      },
      "source": [
        "print(classification_report(y_pred, predictions_friv.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}